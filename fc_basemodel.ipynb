{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d703a2e-3a31-4fec-9889-d70aab84c0a3",
   "metadata": {},
   "source": [
    "# Face classifier - Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c9f6a-6045-4255-af2b-826bf8c19836",
   "metadata": {},
   "source": [
    "In this notebook I train a baseline model in order to establish a minimal value for the performance metric. To do so, I train a simple logistic regression, which is arguably the most simple classification model there is. Using the CNN architectures in the notebook fc_nn.ipynb the goal will be to beat the baseline performance established here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c0102-7540-4c78-ba92-c552a24cdc12",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4be5a-8792-4f83-9ec3-2a58cca9e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score \n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score\n",
    "\n",
    "# Local imports\n",
    "from facecls import fcaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00313a7-1ea9-46fe-84cb-fe4fa4548d3f",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09521b-32c9-461b-818f-facd24fa0b5f",
   "metadata": {},
   "source": [
    "In this section I configure settings and variables. I start by setting the random seed for the sake of reproducibility, I fix the \"target\" and \"model_type\" variables which will be used in several places of this notebook and I create the required folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaaf28f-10d4-4473-b4fa-f88dc90d53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068cab3-27ef-4d27-8e58-936690ca38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "target = \"gender\"\n",
    "model_type = \"logreg\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f18fa1-1c9d-432d-9e0d-6ae793397ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure\n",
    "models_dir = Path(f\"results/models/{target.title()}Classifier/\")\n",
    "\n",
    "try:\n",
    "    last_model_id = max([int(folder.as_posix().split(\"_\")[2]) for folder in models_dir.glob(f'{model_type}*')])\n",
    "except ValueError:\n",
    "    last_model_id = 0\n",
    "\n",
    "print(\"Last model id:\", last_model_id)\n",
    "\n",
    "new_model_id = last_model_id + 1\n",
    "file_suffix = f\"{model_type}_{target}_{str(new_model_id).zfill(3)}\"\n",
    "new_model_dir = models_dir / file_suffix\n",
    "print(f\"Creating folder \\\"{new_model_dir}\\\"...\")\n",
    "new_model_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bec25b-11be-414b-9815-9743234566ef",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42802f02-2302-4e36-b62f-591b3007b30a",
   "metadata": {},
   "source": [
    "Load the data from file and print some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f911a-1b01-4cbd-a8ec-f85cac46c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/age_gender_preproc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a76b7-da7e-47d0-bc58-348f5f19b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126872b5-2f0e-4217-b027-2c0f3878242c",
   "metadata": {},
   "source": [
    "## Baseline model: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc3ffb-fd29-4370-b4d1-c312b61b641f",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1059b-945f-4bc1-901e-7cc6380e5fff",
   "metadata": {},
   "source": [
    "As seen in fc_eda.ipynb, the actual images are stored in the \"pixels\" column of the \"data\" DataFrame in the form of strings of space-separated pixel values. As a preprocessing step conducted in the next cell, this column will be converted into a 2D numpy array. Specifically, each entry (a string) will be converted into a 1D numpy array such that the full column corresponds to a vector of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517188ad-1374-4e15-936b-7cc1ad6848ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img_vec_list = np.array([fcaux.pxlstring2pxlvec(data, i) for i in range(data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2dea2-0bc1-4e9d-bd89-1e7120f6344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img_vec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120c2a8-0014-4dba-ba25-7f98f0422aee",
   "metadata": {},
   "source": [
    "This resulting 2D array represents the input data to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28602822-f3c1-4f40-a7d7-e5cf6f342d8a",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157128f-a6da-4080-b6e9-b99689fa89f9",
   "metadata": {},
   "source": [
    "As usual we split the data set into a training, validation and a test set. The test set is made of 20% of the entire data set, the validation set of 10% of the remaining 80% (i.e. of 8% of the entire data set) and therefore 72% of the full data set make up the training set.\n",
    "\n",
    "*REMARK:* Here, we will only use the training and test set (and not the validation set) as there will be no hyperparameter tuning for this baseline model. But in order use consistent number of examples both in the baseline as well as in the competitor models, the split is performed identically in both cases.\n",
    "\n",
    "Notice that we perform the split using indices and not on the feature and target data directly. The motivation is so we can later just safe the train, validation and test example indices in a CSV file which saves more disk space than saving new copies of the full data for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d9bd9-056e-4eac-a20e-b22d1f5f1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = list(range(len(full_img_vec_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de801d-8eb6-44e8-85d7-b9a625a004ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = data[[\"gender\", \"ethnicity\", \"age_decades\"]]\n",
    "all_indices = range(full_img_vec_list.shape[0])\n",
    "\n",
    "# Stratification is only possible for categorical targets\n",
    "if target == \"age\":\n",
    "    strat = None\n",
    "else:\n",
    "    strat = attrs[target].values\n",
    "\n",
    "# Perform the train-test split\n",
    "idx_train, idx_test = train_test_split(all_indices,\n",
    "                                       test_size = 0.2,\n",
    "                                       stratify = strat,\n",
    "                                       random_state=seed\n",
    "                                      )\n",
    "\n",
    "# Perform the train-val split\n",
    "idx_train, idx_val  = train_test_split(idx_train,\n",
    "                                       test_size = 0.1,\n",
    "                                       stratify = strat[idx_train],\n",
    "                                       random_state=seed\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a188a9-c58e-4e34-b40c-903e72d61017",
   "metadata": {},
   "source": [
    "Now use those indices to extract the corresponding features/images and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c898d0-ed96-48ba-9ba7-12e72990db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract column index for target column ...\n",
    "target_idx = attrs.columns.get_loc(target)\n",
    "\n",
    "# ... because we need this to slice the data sets using iloc\n",
    "X_train = full_img_vec_list[idx_train]\n",
    "y_train = attrs.iloc[idx_train, target_idx]\n",
    "\n",
    "X_val = full_img_vec_list[idx_val]\n",
    "y_val = attrs.iloc[idx_val, target_idx]\n",
    "\n",
    "X_test = full_img_vec_list[idx_test]\n",
    "y_test = attrs.iloc[idx_test, target_idx]\n",
    "attrs_test = attrs.iloc[idx_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c2642-85d4-4a71-b179-4fb6e913d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking: number of elements per data subset\n",
    "print(\"#training:\", len(X_train))\n",
    "print(\"#validation:\", len(X_val))\n",
    "print(\"#test:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693d4bd-72f7-4253-ab14-bd78220c5382",
   "metadata": {},
   "source": [
    "Now save the three different index data sets to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101f67d-e1da-4b20-bc49-5b75b713de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to pack all three index vectors into one single pd.DataFrame\n",
    "# they all need to be of the same length. To achieve this, we fill the\n",
    "# test and validation index vectors with NaNs until they have the same\n",
    "# length as the training index vector.\n",
    "idx_val += (len(idx_train) - len(idx_val))*[np.nan]\n",
    "idx_test += (len(idx_train) - len(idx_test))*[np.nan]\n",
    "\n",
    "# Check that the vectors are now all of equal length\n",
    "assert len(idx_train) == len(idx_val)\n",
    "assert len(idx_train) == len(idx_test)\n",
    "\n",
    "# Pack all three index vectors into a single pd.DataFrame for easy\n",
    "# and convenient writing to file.\n",
    "idx_df = pd.DataFrame({\"train_idx\": idx_train,\n",
    "                       \"val_idx\": idx_val,\n",
    "                       \"test_idx\": idx_test}, dtype=\"Int64\")\n",
    "\n",
    "idx_df.to_csv(new_model_dir / f\"data_set_indices__{file_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5497b3f-9f27-48da-9f47-3a97a859184f",
   "metadata": {},
   "source": [
    "### Training the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb629031-a1f1-41ee-9d67-ea8485fe00e9",
   "metadata": {},
   "source": [
    "As the current goal is merely to establish a baseline model, I construct the logistic regression model using default hyperparameters. I only set the \"random_state\" parameter for reproducibility, the \"n_jobs\" for efficiency and the \"verbose\" for transparancy reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71a233-762f-42e4-86df-24f5a0f10501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the logistic regression model\n",
    "model = LogisticRegression(random_state = seed, \n",
    "                           n_jobs = -1,\n",
    "                           verbose=True\n",
    "                           )\n",
    "\n",
    "# Train the model and measture the time it take to do so.\n",
    "start = dt.now()\n",
    "model.fit(X_train, y_train)\n",
    "elapsed = dt.now()-start\n",
    "print(f\"Elapsed: {elapsed}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ffead-2edb-495f-9c0d-7c17f9862ed4",
   "metadata": {},
   "source": [
    "Use the trained logistic regression model to predict the labels for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930603d-abca-4b79-8592-faf1e52a8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1aa393-c25e-4110-a6b1-7dbead2beb8d",
   "metadata": {},
   "source": [
    "With these results, compute the false positive rate (fpr) and the true positive rate (tpr) various different thresholds (thr), save them to a file and use them to plot the ROC curve as well as to compute the ROC AUC score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8100a-5a0b-4a95-aa50-d78f72022fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ROC curve\n",
    "fpr, tpr, thr = roc_curve(y_test, y_prob_test[:,1])\n",
    "pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr}).to_csv(new_model_dir / f\"fpr_vs_tpr__{file_suffix}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308507bf-c3d8-4bd3-98f7-cfe6c8dcc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the ROC curve plot and compute the ROC AUC metric\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr,tpr)\n",
    "ax.plot([0,1], [0,1], ls=\"--\", c=\"k\")\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(f\"ROC AUC: {np.round(roc_auc_score(y_test, y_prob_test[:,1]),4)}\")\n",
    "plt.savefig(new_model_dir / f\"roc_curve__{file_suffix}.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261f656-1484-45ce-bdf1-375993c2dcfa",
   "metadata": {},
   "source": [
    "Last but not least, compute the performance metrics for all three data sets (train, validation and test) and write them to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7a988-43b8-43c4-b857-aea7760cdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class and probability predictions for all three data sets\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "y_proba_train = model.predict_proba(X_train)\n",
    "y_proba_val = model.predict_proba(X_val)\n",
    "y_proba_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290cf858-de57-4817-a3e5-0017caa3da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classification report and write it to file\n",
    "cls_report = pd.DataFrame(classification_report(y_test, y_pred_test, output_dict=True))\n",
    "cls_report.to_csv(new_model_dir / f\"classificationo_report__{file_suffix}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccac466-2590-4ae3-a1f1-c06b2aabb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more performance metrics and write them to file, too.\n",
    "train_metrics = {\"accuracy\": accuracy_score(y_train, y_pred_train),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(y_train, y_pred_train),\n",
    "                \"roc_auc\": roc_auc_score(y_train, y_proba_train[:,1]),\n",
    "                \"F1\": f1_score(y_train, y_pred_train)}\n",
    "\n",
    "val_metrics = {\"accuracy\": accuracy_score(y_val, y_pred_val),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(y_val, y_pred_val),\n",
    "                \"roc_auc\": roc_auc_score(y_val, y_proba_val[:,1]),\n",
    "                \"F1\": f1_score(y_val, y_pred_val)}\n",
    "\n",
    "test_metrics = {\"accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred_test),\n",
    "                \"roc_auc\": roc_auc_score(y_test, y_proba_test[:,1]),\n",
    "                \"F1\": f1_score(y_test, y_pred_test)}\n",
    "\n",
    "# Organize the results in a data frame for better readability\n",
    "metrics_df = pd.DataFrame({\"train\": train_metrics, \n",
    "                           \"val\": val_metrics, \n",
    "                           \"test\": test_metrics})\n",
    "\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv(new_model_dir / f\"metrics__{file_suffix}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
