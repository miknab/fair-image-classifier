{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d703a2e-3a31-4fec-9889-d70aab84c0a3",
   "metadata": {},
   "source": [
    "# Face classification with CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c0102-7540-4c78-ba92-c552a24cdc12",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4be5a-8792-4f83-9ec3-2a58cca9e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score \n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Local imports\n",
    "from facecls import fcaux, fcmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bec25b-11be-414b-9815-9743234566ef",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Let's load the preprocessed data set from the CSV file. It contains the images and four possible attributes/targets: \"gender\", \"ethnicity\", \"age\", and \"age_decades\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f911a-1b01-4cbd-a8ec-f85cac46c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/age_gender_preproc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7267a-b5a0-40e1-be30-5be06cc96246",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "Next, we define for which of the four targets the classifier shall be trained in this notebook and with what CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7032ed-29bf-4d35-89a0-483eb35a1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"gender\"\n",
    "cnn_architecture = \"alexnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d32b99-c28f-431c-b11a-78449f7481b9",
   "metadata": {},
   "source": [
    "Also, we create a new directory specifically for the model that we will train in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb5e24-1972-4011-aa9e-9138cdbea779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable containing the root directory for all models\n",
    "models_dir = Path(f\"results/models/{target.title()}Classifier/\")\n",
    "\n",
    "# Identify the ID of the last, already existing model of the specified \n",
    "# CNN architecture.\n",
    "try:\n",
    "    last_model_id = max([int(folder.as_posix().split(\"_\")[2]) \n",
    "                         for folder in models_dir.glob(f'{cnn_architecture}*')\n",
    "                        ])\n",
    "except ValueError:\n",
    "    # If no model of the specified architecture exists yet, set the last \n",
    "    # model ID = 0, so that the model created now will have ID = 1\n",
    "    last_model_id = 0 \n",
    "\n",
    "# Just to check that all is right, print the identified ID of the last, existing\n",
    "# model.\n",
    "print(\"Last model id:\", last_model_id)\n",
    "\n",
    "# ID of the model that we will create now\n",
    "new_model_id = last_model_id + 1\n",
    "\n",
    "# Variable file_suffix contains info about the model architecture, the target\n",
    "# and the model ID. This variable will be reused several times in this notebook\n",
    "# and defines a naming convention.\n",
    "file_suffix = f\"{cnn_architecture}_{target}_{str(new_model_id).zfill(3)}\"\n",
    "\n",
    "# Create a directory for the model created here\n",
    "new_model_dir = models_dir / file_suffix\n",
    "print(f\"Creating folder \\\"{new_model_dir}\\\"...\")\n",
    "new_model_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea15cf-c831-4751-a229-b5be363ee4af",
   "metadata": {},
   "source": [
    "## Model build\n",
    "\n",
    "In this section, we will build the classifier using the CNN architecture defined above. The first step to do is to prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb231e39-8807-4d9b-bcfe-b986fdc78510",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = fcaux.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488e4f3-677d-4ecb-9507-0614dcc73ccb",
   "metadata": {},
   "source": [
    "### Convert data from strings (as read from file) to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b9aae-4e0d-401a-9b8c-2076c7b88835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper function to convert the pixel string \n",
    "# first into a pixel vector...\n",
    "full_img_vec_list = np.array([fcaux.pxlstring2pxlvec(data, i) for i in range(data.shape[0])])\n",
    "\n",
    "# ...and then the pixel vector into a pixel array\n",
    "full_img_array_list = np.array([fcaux.pxlvec2pxlarray(img_vec) for img_vec in full_img_vec_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690400a-d40e-494c-84d6-a4bf8b7a19b5",
   "metadata": {},
   "source": [
    "### Data split\n",
    "\n",
    "As usual we split the data set into a training, validation and a test set. The test set is made of 20% of the entire data set, the validation set of 10% of the remaining 80% (i.e. of 8% of the entire data set) and therefore 72% of the full data set make up the training set.\n",
    "\n",
    "Notice that we perform the split using indices and not on the feature and target data directly. The motivation is so we can later just safe the train, validation and test example indices in a CSV file which saves more disk space than saving new copies of the full data for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfea30-925b-4678-b592-7bb01684a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = full_img_array_list\n",
    "attrs = data[[\"gender\", \"ethnicity\", \"age_decades\"]]\n",
    "all_indices = range(len(X_in))\n",
    "\n",
    "# Stratification is only possible for categorical targets\n",
    "if target == \"age\":\n",
    "    strat = None\n",
    "else:\n",
    "    strat = attrs[target].values\n",
    "\n",
    "# Perform the train-test split\n",
    "idx_train, idx_test = train_test_split(all_indices,\n",
    "                                       test_size = 0.2,\n",
    "                                       stratify = strat,\n",
    "                                       random_state=seed\n",
    "                                      )\n",
    "\n",
    "# Perform the train-val split\n",
    "idx_train, idx_val  = train_test_split(idx_train,\n",
    "                                       test_size = 0.1,\n",
    "                                       stratify = strat[idx_train],\n",
    "                                       random_state=seed\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f13848-7dcf-4aa7-9e5b-f66b21c4c0fb",
   "metadata": {},
   "source": [
    "Now use those indices to extract the corresponding features/images and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2c0b2-6a21-497c-8a98-cb24095126cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_in[idx_train]\n",
    "y_train = attrs.iloc[idx_train, target]\n",
    "\n",
    "X_val = X_in[idx_val]\n",
    "y_val = attr.iloc[idx_val, target]\n",
    "\n",
    "X_test = X_in[idx_test]\n",
    "y_test = attr.iloc[idx_test, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dfb7f-450c-4f82-a5f4-167ee23f433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking: number of elements per data subset\n",
    "print(\"#training:\", len(X_train))\n",
    "print(\"#validation:\", len(X_val))\n",
    "print(\"#test:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8b240-7b80-4a35-ae42-d5acd4447d84",
   "metadata": {},
   "source": [
    "Now save the three different index data sets to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb83dc-d1b7-4c7c-b4f4-fc941acae340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to pack all three index vectors into one single pd.DataFrame\n",
    "# they all need to be of the same length. To achieve this, we fill the\n",
    "# test and validation index vectors with NaNs until they have the same\n",
    "# length as the training index vector.\n",
    "idx_val += (len(idx_train) - len(idx_val))*[np.nan]\n",
    "idx_test += (len(idx_train) - len(idx_test))*[np.nan]\n",
    "\n",
    "# Check that the vectors are now all of equal length\n",
    "assert len(idx_train) == len(idx_val)\n",
    "assert len(idx_train) == len(idx_test)\n",
    "\n",
    "# Pack all three index vectors into a single pd.DataFrame for easy\n",
    "# and convenient writing to file.\n",
    "idx_df = pd.DataFrame({\"train_idx\": idx_train,\n",
    "                       \"val_idx\": idx_val,\n",
    "                       \"test_idx\": idx_test}, dtype=\"Int64\")\n",
    "\n",
    "idx_df.to_csv(new_model_dir / f\"data_set_indices__{file_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e9e2b-e332-4fc1-bda2-19d6fe409702",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "In order to train the model later on, we first need to make sure the data is in a suitable format. Specifically this means:\n",
    "\n",
    "- the input tensors X_* need to be of shape (n_X, width, height, n_channels), where n_X is the number of examples in the tensor X_*, width and height are the pixel dimensions of each image and n_channels is the number of channels used in the image. Specifically, we are working with grayscale images, i.e. n_channels = 1.\n",
    "- The pixel values need to be of type float\n",
    "- The pixel values need to be normalized to the range between [0,1].\n",
    "- If the target is age_decades, we need to make sure the age_decade classes are labelled by consecutive indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915ae48-84c4-43da-b926-c7205f0fb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample images if required by CNN architecture\n",
    "if cnn_architecture in [\"LeNet\", \"AlexNet\", \"VGG\", \"ResNet\"]:\n",
    "    newdim = 227\n",
    "    X_train = np.array([fcaux.upsample_image(X_train, newdim, newdim) for X in X_train])\n",
    "    X_val = np.array([fcaux.upsample_image(X_val, newdim, newdim) for X in X_val])\n",
    "    X_test = np.array([fcaux.upsample_image(X_test, newdim, newdim) for X in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15455a88-020c-43ca-9e69-bc510024f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data: fix the shape and data type and normalize\n",
    "X_train = fcaux.preproc_data(X_train)\n",
    "X_val = fcaux.preproc_data(X_val)\n",
    "X_test = fcaux.preproc_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9ab82-b0c0-48ee-9c75-97db1775a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the target is \"age_decades\", we need to generate consecutive data\n",
    "# classes as classes 10, 20, 30 etc. or 5, 10, 15, etc. are not accepted\n",
    "# by keras.utils.to_categorical called below\n",
    "if target == \"age_decades\":\n",
    "    y_train /= age_diff\n",
    "    y_val /= age_diff\n",
    "    y_test /= age_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113635ff-1de2-418a-87c4-cb170a4f9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of classes for the current classification problem.\n",
    "# This number will be the dimension of the output layer in the neural \n",
    "# network to be built.\n",
    "if target == \"age\":\n",
    "    # If target == \"age\", we are solving a regression and not a classifiction\n",
    "    # problem, i.e. there are no classes. \n",
    "    num_classes = 0\n",
    "else:\n",
    "    num_classes = data[target].nunique()\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "print(\"num_classes =\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffaf94-cd2e-41a8-b71e-fc8fea56c4dd",
   "metadata": {},
   "source": [
    "### Building the CNN model \n",
    "Here we define the model according to the CNN architecture definition specified in the configurations section above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45dc330-5106-4517-8afa-a295f5a49981",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnn_architecture == \"mycnn\":\n",
    "    model = fcmodels.my_cnn(num_classes)\n",
    "elif cnn_architecture == \"lenet\":\n",
    "    pass\n",
    "elif cnn_architecture == \"alexnet\":\n",
    "    model = fcmodels.alex_net(num_classes)\n",
    "elif cnn_architecture == \"vgg\":\n",
    "    pass\n",
    "elif cnn_architecture == \"resnet\":\n",
    "    pass\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356273cc-011f-490a-8b81-dc108bce0846",
   "metadata": {},
   "source": [
    "### Train model until overfitting\n",
    "Now we are finally ready to train the model. We do so by fitting the previously defined model to the training data for a maximal number n_epochs epochs. During the training, we measure the validation loss and use early stopping based on the validation loss in order to avoid overfitting. We use this approach not just find the optimal value of epochs but also to generate evidence that if more epochs are used the model would overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370ab73-2d95-4dd7-b896-9093c8145cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of epochs\n",
    "n_epochs = 30\n",
    "\n",
    "# Definition of early stopping callback: make sure to restore the best weights\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[early_stopping]\n",
    "                   )\n",
    "\n",
    "# Save the optimal model\n",
    "model.save(new_model_dir / f'{file_suffix}__nepochs{n_epochs}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08f4f6-9e02-4809-8dff-c4adabadcc28",
   "metadata": {},
   "source": [
    "Let's now have a look at the loss curve to make sure the training process went as expected. First we put the data in a pandas.DataFrame, then we save that to a CSV file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047264f0-fe17-42c9-b74d-6005cfc37f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history.history  # Just for simplification/convenience\n",
    "\n",
    "# Add an explicit \"epoch\" key with values enumerating the epochs\n",
    "history[\"epoch\"] = list(range(1, n_epochs+1))\n",
    "\n",
    "# In general we don't know the names of the other keys of the history dictionary\n",
    "# as they depend on the specific configuration of the model training process.\n",
    "# Therefore, extract those unknown keys.\n",
    "other_columns = [k for k, v in history.items() if k!=\"epoch\"] \n",
    "\n",
    "# Convert the history dictionary into a dataframe (with 'epoch' as first column)\n",
    "# for convenient saving.\n",
    "history_df = pd.DataFrame(history, columns = [\"epoch\"] + other_columns)\n",
    "file_name = f'history__{file_suffix}__nepochs{n_epochs}.csv'\n",
    "history_df.to_csv(new_model_dir / file_name, index=False)\n",
    "\n",
    "# Remark: by creating the column \"epoch\" and by setting the index kwarg in\n",
    "# the last line to False, the epoch enumarting column has actually in the\n",
    "# saved CSV file (otherwise there wouldn't be a name and when loading the file\n",
    "# again from disk there would be a generic \"Unnamed: 0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01858b56-badc-4aee-a006-3ee9a941d85c",
   "metadata": {},
   "source": [
    "...and last but not least, we plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d27cb8-61dc-4c44-af36-29c658d988df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(5,4), sharex=True)\n",
    "ax = axs[0]  # panel for loss curves\n",
    "ax.plot(an_history.history[\"loss\"], label=\"training\")\n",
    "ax.plot(an_history.history[\"val_loss\"], label=\"validation\")\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(f\"AlexNet ({target.title()})\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax = axs[1]  # panel for accuracy curves\n",
    "ax.plot(an_history.history[\"accuracy\"], label=\"training\")\n",
    "ax.plot(an_history.history[f\"val_accuracy\"], label=\"validation\")\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "# Save figure to disk\n",
    "plt.savefig(new_model_dir / f\"loss_curve__{file_suffix}__nepochs{n_epochs}.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b6ff8-4486-44d0-9df1-93b05a0e648f",
   "metadata": {},
   "source": [
    "### Refit model with optimal number of epochs\n",
    "\n",
    "Remark: optimal number of epochs = number of epochs leading to minimal validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da928a-5202-4f06-979a-8273c67fc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()\n",
    "n_epochs = np.argmin(an_history.history[\"val_loss\"])\n",
    "print(f\"Optimal epoch: #{n_epochs}.\")\n",
    "alex_net_refit = create_alex_net_model(num_classes)\n",
    "\n",
    "refit_history = alex_net_refit.fit(X_train, y_train,\n",
    "                                   epochs=n_epochs,\n",
    "                                   batch_size=32,\n",
    "                                   validation_data=(X_val, y_val),\n",
    "                                   shuffle=True\n",
    "                                  )    \n",
    "\n",
    "alex_net_refit.save(new_model_dir / f'{file_suffix}__refit_nepochs{n_epochs}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65feabb0-a95f-4246-8168-dda62475bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "refit_history = alex_net_refit.history.history\n",
    "n_epochs = len(refit_history[list(refit_history.keys())[0]])\n",
    "history[\"epoch\"] = list(range(1, n_epochs+1))\n",
    "\n",
    "# in general I don't know the names of the other columns. Therefore:\n",
    "other_columns = [k for k, v in refit_history.items() if k!=\"epoch\"] \n",
    "\n",
    "refit_history_df = pd.DataFrame(refit_history, columns = [\"epoch\"] + other_columns)\n",
    "file_name = f'history__{file_suffix}__refit__nepochs{n_epochs}.csv'\n",
    "#refit_history_df.to_csv(new_model_dir / file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58ef33-fac6-4183-b2a6-146b9d614ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(5,4), sharex=True)\n",
    "ax = axs[0]\n",
    "ax.plot(refit_history[\"loss\"], label=\"training\")\n",
    "ax.plot(refit_history[\"val_loss\"], label=\"validation\")\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(f\"AlexNet ({target.title()})\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(refit_history[\"accuracy\"], label=\"training\")\n",
    "ax.plot(refit_history[f\"val_accuracy\"], label=\"validation\")\n",
    "ax.grid(True)\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")#metric.title())\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.savefig(new_model_dir / f\"loss_curve__{file_suffix}__refit_nepochs{n_epochs}.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f9644-eadd-4f90-a204-8856a1abb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train = alex_net.predict(X_train)\n",
    "y_pred_train = np.array([np.argmax(i) for i in y_prob_train])\n",
    "\n",
    "y_prob_val = alex_net.predict(X_val)\n",
    "y_pred_val = np.array([np.argmax(i) for i in y_prob_val])\n",
    "\n",
    "y_prob_test = alex_net.predict(X_test)\n",
    "y_pred_test = np.array([np.argmax(i) for i in y_prob_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03160d32-1010-4a1d-87f1-7e332107f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = {\"accuracy\": accuracy_score(np.array([np.argmax(i) for i in y_train]), y_pred_train),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(np.array([np.argmax(i) for i in y_train]), y_pred_train),\n",
    "                \"roc_auc\": roc_auc_score(np.array([np.argmax(i) for i in y_train]), y_prob_train[:,1]),\n",
    "                \"F1\": f1_score(np.array([np.argmax(i) for i in y_train]), y_pred_train)}\n",
    "\n",
    "val_metrics = {\"accuracy\": accuracy_score(np.array([np.argmax(i) for i in y_val]), y_pred_val),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(np.array([np.argmax(i) for i in y_val]), y_pred_val),\n",
    "                \"roc_auc\": roc_auc_score(np.array([np.argmax(i) for i in y_val]), y_prob_val[:,1]),\n",
    "                \"F1\": f1_score(np.array([np.argmax(i) for i in y_val]), y_pred_val)}\n",
    "\n",
    "test_metrics = {\"accuracy\": accuracy_score(y_test, y_pred_test),\n",
    "                \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred_test),\n",
    "                \"roc_auc\": roc_auc_score(y_test, y_prob_test[:,1]),\n",
    "                \"F1\": f1_score(y_test, y_pred_test)}\n",
    "\n",
    "metrics_df = pd.DataFrame({\"train\": train_metrics, \n",
    "                           \"val\": val_metrics, \n",
    "                           \"test\": test_metrics})\n",
    "\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv(new_model_dir / f\"metrics__{file_suffix}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c31df2-5e3a-4063-a73d-fb24277a2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, y_prob_test[:,1])\n",
    "pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr}).to_csv(new_model_dir / f\"fpr_vs_tpr__{file_suffix}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabda4a-a6c3-4854-9b3b-18685f23a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr,tpr)\n",
    "ax.plot([0,1], [0,1], ls=\"--\", c=\"k\")\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(f\"{target.title()} -- ROC AUC: {np.round(roc_auc_score(y_test, y_prob_test[:,1]),4)}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(new_model_dir / f\"roc_curve__{file_suffix}.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7653854-24ca-4abf-a9ce-0c2b868f0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_report = pd.DataFrame(classification_report(y_test, y_pred_test, output_dict=True))\n",
    "cls_report.to_csv(new_model_dir / f\"classificationo_report__{file_suffix}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3833330-dcfe-470c-ac9b-a0dfb1af2d6d",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181057f-49e5-40ec-ac38-121a03a39324",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[[i for i in idx_test if i==i]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be5b2f-7752-415d-9347-8054c80ecdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_groups = dict()\n",
    "\n",
    "for ethn_idx in test_data[\"ethnicity\"].unique():\n",
    "    ethnicity_groups[ethn_idx] = list(test_data[test_data[\"ethnicity\"]==ethn_idx].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067a05b-52ad-467a-860d-42a0302e0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_ethnicity = dict()\n",
    "for ethn in range(5):\n",
    "    y_prob_ethn = alex_net.predict(X_test[ethnicity_groups[ethn]])\n",
    "    y_pred_ethn = np.array([np.argmax(i) for i in y_prob_ethn])\n",
    "    acc = accuracy_score(y_test[ethnicity_groups[ethn]], y_pred_ethn)\n",
    "    rocauc = roc_auc_score(y_test[ethnicity_groups[ethn]], y_prob_ethn[:,1])\n",
    "\n",
    "    performance_by_ethnicity[ethn] = {\"accuracy\": acc, \n",
    "                                      \"ROC_AUC\": rocauc}\n",
    "\n",
    "# Convert to data frame for easier plotting\n",
    "performance_by_ethnicity_df = pd.DataFrame(performance_by_ethnicity).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ec0c2-efc7-4c4c-bc9a-eb6e21d8aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = dict()\n",
    "\n",
    "for age_idx in test_data[\"age_decades\"].unique():\n",
    "    age_groups[age_idx] = list(test_data[test_data[\"age_decades\"]==age_idx].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29840e-257a-4047-b2e3-81da37c20385",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_age = dict()\n",
    "for age_idx in test_data[\"age_decades\"].unique():\n",
    "    y_prob_age = alex_net.predict(X_test[age_groups[age_idx]])\n",
    "    y_pred_age = np.array([np.argmax(i) for i in y_prob_age])\n",
    "    acc = accuracy_score(y_test[age_groups[age_idx]], y_pred_age)\n",
    "    try:\n",
    "        rocauc = roc_auc_score(y_test[age_groups[age_idx]], y_prob_age[:,1])\n",
    "    except ValueError:\n",
    "        rocauc = np.nan\n",
    "\n",
    "    performance_by_age[age_idx] = {\"accuracy\": acc, \n",
    "                                      \"ROC_AUC\": rocauc}\n",
    "\n",
    "sorted_columns = sorted([k for k,v in performance_by_age.items()])\n",
    "performance_by_age_df = pd.DataFrame(performance_by_age, \n",
    "                                     columns = sorted_columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7dcb44-2cc7-4110-b3da-89ce57c3687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,4), sharey=True, gridspec_kw = {\"hspace\": 0.07})\n",
    "ax = axs[0]\n",
    "performance_by_ethnicity_df.plot(kind=\"bar\", ax = ax, grid=True, legend=False)\n",
    "ax.set_xlabel(\"Ethnicity\")\n",
    "ax.set_ylabel(\"Metric\")\n",
    "\n",
    "ax = axs[1]\n",
    "performance_by_age_df.plot(kind=\"bar\", ax = ax, grid=True)\n",
    "ax.set_xlabel(\"Age (decade)\")\n",
    "ax.legend(loc=\"center\", bbox_to_anchor=(-0.15,-0.2), ncol=2)\n",
    "\n",
    "fig.suptitle(\"Classification performance by ethnicity and age group\")\n",
    "\n",
    "plt.savefig(new_model_dir / f\"cls_performance_analysis__{file_suffix}\", \n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7332-6518-4985-81f7-c4cedc0e5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_groups = dict()\n",
    "\n",
    "for gen_idx in test_data[\"gender\"].unique():\n",
    "    gender_groups[gen_idx] = list(test_data[test_data[\"gender\"]==gen_idx].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f4016-4d58-40f4-96b6-a1ed95e66b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_gender = dict()\n",
    "for gen_idx in test_data[\"gender\"].unique():\n",
    "    y_prob_gen = alex_net.predict(X_test[gender_groups[gen_idx]])\n",
    "    y_pred_gen = np.array([np.argmax(i) for i in y_prob_gen])\n",
    "    acc = accuracy_score(y_test[gender_groups[gen_idx]], y_pred_gen)\n",
    "    try:\n",
    "        rocauc = roc_auc_score(y_test[gender_groups[gen_idx]], y_prob_gen[:,1])\n",
    "    except ValueError:\n",
    "        rocauc = np.nan\n",
    "\n",
    "    performance_by_gender[gen_idx] = {\"accuracy\": acc, \n",
    "                                      \"ROC_AUC\": rocauc}\n",
    "\n",
    "sorted_columns = sorted([k for k,v in performance_by_gender.items()])\n",
    "performance_by_gender_df = pd.DataFrame(performance_by_gender, \n",
    "                                     columns = sorted_columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e7846-af2a-42f6-ac10-c1d1dc778b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768a90b-1ac0-47d9-9c96-594d338c2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(10,4), sharey=True, gridspec_kw = {\"hspace\": 0.07})\n",
    "ax = axs[0]\n",
    "performance_by_ethnicity_df.plot(kind=\"bar\", ax = ax, grid=True, legend=False)\n",
    "ax.set_xlabel(\"Ethnicity\")\n",
    "ax.set_ylabel(\"Metric\")\n",
    "\n",
    "ax = axs[1]\n",
    "performance_by_age_df.plot(kind=\"bar\", ax = ax, grid=True)\n",
    "ax.set_xlabel(\"Age (decade)\")\n",
    "ax.legend(loc=\"center\", bbox_to_anchor=(-0.15,-0.2), ncol=2)\n",
    "\n",
    "ax = axs[2]\n",
    "performance_by_gender_df.plot(kind=\"bar\", ax = ax, grid=True)\n",
    "ax.set_xlabel(\"Gender\")\n",
    "#ax.legend(loc=\"center\", bbox_to_anchor=(-0.15,-0.2), ncol=2)\n",
    "\n",
    "fig.suptitle(\"Classification performance by ethnicity and age group\")\n",
    "\n",
    "#plt.savefig(new_model_dir / f\"cls_performance_analysis__{file_suffix}\", \n",
    "#            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b6fde-36d2-439b-8f16-922235bd227c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
